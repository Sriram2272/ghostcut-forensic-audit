# ğŸ”ª GHOSTCUT  
### Cutting Hallucinations Out of AI

ğŸš€ **Live Demo:** https://sriramdama.in  
ğŸ‘¥ **Team:** AVENGERS  
ğŸ† **Built for:** IIT Roorkee E-Summit Hackathon

---

## ğŸ§  What is GHOSTCUT?

LLMs are smart.  
LLMs are confident.  
LLMs are also **sometimes confidently wrong**.

**GHOSTCUT** is an **AI Auditor for AI-generated content**.

It doesnâ€™t *generate* text.  
It **verifies**, **cross-checks**, and **cuts hallucinations** before they reach humans.

Think of it as:
> ğŸ” *A lie detector for AI outputs.*

---

## âŒ The Problem

Modern LLMs:
- Hallucinate subtle facts
- Mix correct and incorrect information
- Provide no source traceability
- Are dangerous in **healthcare, law, finance, and enterprise systems**

Manual verification:
- Is slow
- Is expensive
- Does not scale

ğŸ‘‰ **Trust is the real bottleneck for AI adoption.**

---

## âœ… The Solution â€” GHOSTCUT

GHOSTCUT acts as a **verification layer** between AI outputs and users.

It:
- Breaks AI output into **atomic factual claims**
- Verifies each claim **only against uploaded documents**
- Classifies claims as:
  - ğŸŸ¢ Supported
  - ğŸ”´ Contradicted
  - ğŸŸ¡ No Direct Evidence Found
- Explains **why**, **where**, and **how confident** each verdict is
- Computes a **real, auditable Trust Score**

No internet guessing.  
No black-box answers.  
No hallucination amplification.

---

## âš™ï¸ How It Works (High Level)

AI Output
â†“
Claim Decomposition
â†“
Evidence Retrieval (Document-Bounded)
â†“
Claim Verification (NLI)
â†“
Explainability + Trust Scoring


Every step is **deterministic**, **auditable**, and **explainable**.

---

## ğŸ§© Tech Stack (Verification-First Design)

### ğŸ” NLP & ML Models
- **Sentence-BERT (SBERT)**  
  â†’ Semantic retrieval of relevant document chunks
- **TF-IDF (Classical NLP)**  
  â†’ Fast, deterministic first-pass filtering
- **RoBERTa / DeBERTa (NLI Models)**  
  â†’ Claimâ€“evidence entailment & contradiction detection

> âš ï¸ No large generative models are used for verification.

---

### ğŸ—ï¸ System Architecture
- Stateless verification APIs
- Modular pipeline:
  - Claim Decomposition
  - Retrieval
  - Verification
  - Explanation
- **Chunk-level & claim-level caching**
  â†’ Faster re-audits, lower latency

---

## ğŸ“Š Key Features

- ğŸ¯ **Claim-Level Fact Checking**
- ğŸ”— **Exact Evidence Citations**
- ğŸ§  **Logical & Cascade Hallucination Detection**
- ğŸ“‰ **Math-Based Trust Score**
- âš ï¸ **Risk Classification (Low / Medium / High)**
- ğŸ§­ **Human-Readable Explainability**
- ğŸ“Š **Interactive Dependency Graph**
- ğŸŒ **Web App + WhatsApp Integration Ready**

---

## ğŸ’¼ Real-World Use Cases

- ğŸ¥ Medical report auditing
- âš–ï¸ Legal document verification
- ğŸ’° Financial & compliance checks
- ğŸ¤– AI copilots with guardrails
- ğŸ¢ Enterprise AI deployments

If AI is used in **high-stakes decisions**, GHOSTCUT belongs there.

---

## ğŸ’° Business & Scalability

### Who Pays?
- Enterprises using LLMs
- Legal & compliance teams
- Healthcare & FinTech companies
- AI platform providers

### Revenue Model
- SaaS subscriptions
- API-based usage pricing
- Enterprise licensing
- Messaging-platform (WhatsApp) integrations

### Why It Scales
- Low marginal compute cost
- High trust value
- Easy integration into existing AI pipelines

---

## ğŸŒ Live Demo

ğŸ‘‰ **Try it live:** https://sriramdama.in  

Upload a document.  
Paste AI output.  
Watch hallucinations get **cut**.

---

## ğŸ Final Thought

AI is powerful.  
AI is fast.  
But **AI without verification is dangerous**.

> **If AI writes the future, GHOSTCUT verifies it.**

---

ğŸ”¥ Built with logic, not vibes  
ğŸ”¥ Audited, not assumed  
ğŸ”¥ Hallucinations â€” terminated

â€” **Team AVENGERS**
